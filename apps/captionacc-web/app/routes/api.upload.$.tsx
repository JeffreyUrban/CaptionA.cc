/**
 * Tus resumable upload endpoint
 *
 * Handles chunked, resumable video uploads using the tus protocol
 */

import type { LoaderFunctionArgs, ActionFunctionArgs } from 'react-router'

// Lazy-load Node.js modules to avoid Vite bundling issues
let uploadDir: string | null = null

async function getUploadDir(): Promise<string> {
  if (uploadDir) return uploadDir

  const { resolve } = await import('path')
  const { mkdirSync } = await import('fs')

  uploadDir = resolve(process.cwd(), '..', '..', 'local', 'uploads')
  mkdirSync(uploadDir, { recursive: true })

  return uploadDir
}

interface UploadMetadata {
  videoPath: string // display_path (user-facing path like "level1/video") - legacy, may be removed
  filename: string
  filetype?: string
  videoId?: string // UUID for this video (generated by upload API)
  storagePath?: string // hash-bucketed path like "a4/a4f2b8c3-..." (for local temp storage)
}

// Simple tus protocol implementation without tus-node-server
// This avoids the Node.js/Web API incompatibility issue

async function handleTusRequest(request: Request): Promise<Response> {
  const method = request.method
  const url = new URL(request.url)
  const uploadId = url.pathname.split('/').pop() ?? ''

  console.log(`[tus] ${method} ${url.pathname}`)

  if (method === 'POST') {
    // Create new upload
    return handleCreateUpload(request)
  } else if (method === 'HEAD') {
    // Get upload offset
    return handleHeadRequest(uploadId)
  } else if (method === 'PATCH') {
    // Upload chunk
    return handlePatchRequest(request, uploadId)
  } else if (method === 'OPTIONS') {
    // CORS preflight
    return new Response(null, {
      status: 204,
      headers: {
        'Tus-Resumable': '1.0.0',
        'Tus-Version': '1.0.0',
        'Tus-Extension': 'creation,termination',
        'Access-Control-Allow-Origin': '*',
        'Access-Control-Allow-Methods': 'POST,HEAD,PATCH,OPTIONS',
        'Access-Control-Allow-Headers':
          'Upload-Offset,Upload-Length,Tus-Resumable,Upload-Metadata,Content-Type',
        'Access-Control-Expose-Headers': 'Upload-Offset,Location,Upload-Length,Tus-Resumable',
      },
    })
  }

  return new Response('Method not allowed', { status: 405 })
}

async function handleCreateUpload(request: Request): Promise<Response> {
  const uploadLength = request.headers.get('Upload-Length')
  const uploadMetadata = request.headers.get('Upload-Metadata')

  if (!uploadLength) {
    return new Response('Upload-Length header required', { status: 400 })
  }

  // Parse metadata
  const metadata: UploadMetadata = parseUploadMetadata(uploadMetadata ?? '')

  if (!metadata.videoPath || !metadata.filename) {
    return new Response('videoPath and filename metadata required', { status: 400 })
  }

  // Load Node.js modules
  const { resolve } = await import('path')
  const { createWriteStream, mkdirSync } = await import('fs')
  const { randomUUID } = await import('crypto')

  // Generate upload ID and video UUID
  const uploadDir = await getUploadDir()
  const uploadId = randomUUID()
  const uploadPath = resolve(uploadDir, uploadId)
  const metadataPath = resolve(uploadDir, `${uploadId}.json`)

  // Generate UUID for video storage (stable identifier)
  const videoId = randomUUID()
  const storagePath = `${videoId.slice(0, 2)}/${videoId}` // Hash-bucketed path

  // Save metadata (including videoId and storagePath)
  await writeJSON(metadataPath, {
    uploadId,
    uploadLength: parseInt(uploadLength),
    metadata: {
      ...metadata,
      videoId,
      storagePath,
    },
    createdAt: new Date().toISOString(),
    offset: 0,
  })

  // Create empty file
  createWriteStream(uploadPath).end()

  // Create video directory (for storing the final video file during processing)
  const videoDir = resolve(
    process.cwd(),
    '..',
    '..',
    'local',
    'processing',
    ...storagePath.split('/')
  )
  mkdirSync(videoDir, { recursive: true })

  console.log(`[tus] Created upload: ${uploadId} (video ID: ${videoId})`)

  return new Response(null, {
    status: 201,
    headers: {
      'Tus-Resumable': '1.0.0',
      Location: `/api/upload/${uploadId}`,
      'Upload-Offset': '0',
      'Access-Control-Allow-Origin': '*',
      'Access-Control-Expose-Headers': 'Location,Upload-Offset,Tus-Resumable',
    },
  })
}

async function handleHeadRequest(uploadId: string): Promise<Response> {
  const { resolve } = await import('path')
  const { existsSync, statSync } = await import('fs')

  const uploadDir = await getUploadDir()
  const metadataPath = resolve(uploadDir, `${uploadId}.json`)

  if (!existsSync(metadataPath)) {
    return new Response('Upload not found', { status: 404 })
  }

  const metadata = await readJSON(metadataPath)
  const uploadPath = resolve(uploadDir, uploadId)
  const currentSize = existsSync(uploadPath) ? statSync(uploadPath).size : 0

  return new Response(null, {
    status: 200,
    headers: {
      'Tus-Resumable': '1.0.0',
      'Upload-Offset': currentSize.toString(),
      'Upload-Length': metadata.uploadLength.toString(),
      'Cache-Control': 'no-store',
      'Access-Control-Allow-Origin': '*',
      'Access-Control-Expose-Headers': 'Upload-Offset,Upload-Length,Tus-Resumable',
    },
  })
}

async function handlePatchRequest(request: Request, uploadId: string): Promise<Response> {
  const { resolve } = await import('path')
  const { existsSync, statSync, createWriteStream, unlinkSync } = await import('fs')

  const uploadDir = await getUploadDir()
  const metadataPath = resolve(uploadDir, `${uploadId}.json`)

  if (!existsSync(metadataPath)) {
    return new Response('Upload not found', { status: 404 })
  }

  const metadata = await readJSON(metadataPath)
  const uploadPath = resolve(uploadDir, uploadId)
  const uploadOffset = parseInt(request.headers.get('Upload-Offset') ?? '0')
  const currentSize = existsSync(uploadPath) ? statSync(uploadPath).size : 0

  if (uploadOffset !== currentSize) {
    return new Response('Upload-Offset mismatch', { status: 409 })
  }

  // Append chunk to file
  const arrayBuffer = await request.arrayBuffer()
  const chunk = Buffer.from(arrayBuffer)

  await new Promise((resolve, reject) => {
    const stream = createWriteStream(uploadPath, { flags: 'a' })
    stream.write(chunk, err => {
      if (err) reject(err)
      else resolve(undefined)
    })
    stream.end()
  })

  const newSize = currentSize + chunk.length
  const complete = newSize >= metadata.uploadLength

  if (complete) {
    // Upload complete - move file to final location
    const storagePath = metadata.metadata.storagePath
    if (!storagePath) {
      throw new Error('Storage path missing from metadata')
    }

    const finalVideoPath = resolve(
      process.cwd(),
      '..',
      '..',
      'local',
      'processing',
      ...storagePath.split('/'),
      metadata.metadata.filename
    )

    const fs = await import('fs/promises')
    await fs.rename(uploadPath, finalVideoPath)
    unlinkSync(metadataPath)

    console.log(`[tus] Upload complete: ${finalVideoPath}`)

    // Get authenticated user from Authorization header (localStorage auth)
    const authHeader = request.headers.get('Authorization')
    const token = authHeader?.replace('Bearer ', '')

    let user = null
    let tenantId: string | null = null

    if (token) {
      const { supabase } = await import('~/services/supabase-client')
      const {
        data: { user: authUser },
      } = await supabase.auth.getUser(token)

      user = authUser

      if (user) {
        // Get tenant_id from user_profiles table using service role (bypasses RLS)
        const { createServerSupabaseClient } = await import('~/services/supabase-client')
        const serviceSupabase = createServerSupabaseClient()

        const { data: profile, error: profileError } = await serviceSupabase
          .from('user_profiles')
          .select('tenant_id')
          .eq('id' as never, user.id as never)
          .single()

        if (profileError) {
          console.error(`[Upload] Failed to fetch user profile:`, profileError)
        }

        if (profile && 'tenant_id' in profile) {
          tenantId = profile.tenant_id as string | null
        }
        console.log(`[Upload] User: ${user.id}, Tenant: ${tenantId}`)
      }
    } else {
      console.warn('[Upload] No Authorization header found!')
    }

    if (!user) {
      console.warn('[Upload] No authenticated user found!')
    }

    // Create Supabase entry for the video (using service role to bypass RLS)
    console.log('[Supabase] Creating video entry...')
    const { createServerSupabaseClient } = await import('~/services/supabase-client')
    const supabase = createServerSupabaseClient()

    const { data: videoEntry, error: dbError } = await supabase
      .from('videos')
      .insert({
        id: metadata.metadata.videoId,
        video_path: metadata.metadata.videoPath, // Display path like "level1/video" for tree structure
        size_bytes: metadata.uploadLength,
        storage_key: `processing/${storagePath}/${metadata.metadata.filename}`, // Temporary local path
        status: 'processing',
        tenant_id: tenantId,
        uploaded_by_user_id: user?.id ?? null,
      } as never)
      .select()
      .single()

    if (dbError) {
      console.error('[Supabase] ❌ Failed to create video entry:', dbError)
    } else if (videoEntry && 'id' in videoEntry) {
      console.log(`[Supabase] ✅ Video entry created: ${videoEntry.id}`)
    }

    // Queue video for Wasabi upload and processing via Prefect
    console.log('[Prefect] Queuing upload and processing workflow...')
    const { queueUploadAndProcessing } = await import('~/services/prefect')

    try {
      console.log(`[Prefect] Video ID: ${metadata.metadata.videoId}`)
      console.log(`[Prefect] Video path: ${finalVideoPath}`)
      console.log(`[Prefect] Filename: ${metadata.metadata.filename}`)
      console.log(`[Prefect] File size: ${metadata.uploadLength} bytes`)

      const result = await queueUploadAndProcessing({
        videoPath: finalVideoPath,
        videoId: metadata.metadata.videoId!,
        filename: metadata.metadata.filename,
        fileSize: metadata.uploadLength,
        frameRate: 0.1,
      })
      console.log(`[Prefect] ✅ Successfully queued upload and processing: ${result.flowRunId}`)
    } catch (error) {
      console.error('[Prefect] ❌ Failed to queue workflow:', error)
      console.error(
        '[Prefect] Error stack:',
        error instanceof Error ? error.stack : 'No stack trace'
      )
      // Prefect flow will update video status on failure
    }
  }

  // Build response headers
  const responseHeaders: Record<string, string> = {
    'Tus-Resumable': '1.0.0',
    'Upload-Offset': newSize.toString(),
    'Access-Control-Allow-Origin': '*',
    'Access-Control-Expose-Headers': 'Upload-Offset,Tus-Resumable',
  }

  // Add video ID for complete uploads so frontend can reference it
  if (complete) {
    const videoId = metadata.metadata.videoId
    if (videoId) {
      responseHeaders['X-Video-Id'] = videoId
      responseHeaders['Access-Control-Expose-Headers'] += ',X-Video-Id'
    }
  }

  return new Response(null, {
    status: 204,
    headers: responseHeaders,
  })
}

function parseUploadMetadata(metadataHeader: string): UploadMetadata {
  const metadata: Record<string, string> = {}
  const pairs = metadataHeader.split(',')

  for (const pair of pairs) {
    const [key, value] = pair.trim().split(' ')
    if (key && value) {
      // Use atob for browser compatibility (though this only runs server-side)
      const decoded =
        typeof Buffer !== 'undefined' ? Buffer.from(value, 'base64').toString('utf-8') : atob(value)
      metadata[key] = decoded
    }
  }

  return metadata as unknown as UploadMetadata
}

interface UploadMetadataFile {
  uploadId: string
  uploadLength: number
  metadata: UploadMetadata
  createdAt: string
  offset: number
}

async function readJSON(path: string): Promise<UploadMetadataFile> {
  const { readFile } = await import('fs/promises')
  const content = await readFile(path, 'utf-8')
  return JSON.parse(content) as UploadMetadataFile
}

async function writeJSON(path: string, data: unknown): Promise<void> {
  const fs = await import('fs/promises')
  await fs.writeFile(path, JSON.stringify(data, null, 2), 'utf-8')
}

// Handle all tus protocol methods
export async function loader({ request }: LoaderFunctionArgs) {
  return handleTusRequest(request)
}

export async function action({ request }: ActionFunctionArgs) {
  return handleTusRequest(request)
}
